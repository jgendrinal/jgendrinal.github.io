<!DOCTYPE html>
<html
  class=""
  lang="en-us"
  prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb#"
>
  <head>
    <meta charset="utf-8" />

    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="description" content="" />
<meta name="HandheldFriendly" content="True" />
<meta name="MobileOptimized" content="320" />
<meta name="viewport" content="width=device-width, initial-scale=1" />


<meta name="keywords" content="">


<meta property="og:type" content="article" />
<meta property="og:description" content="" />
<meta property="og:title" content="The breast cancer dataset" />
<meta property="og:site_name" content="The data salaryman" />
<meta property="og:image" content="/images/breastcancer-og-thumbnail.png" />
<meta property="twitter:card" content="summary_large_image" />
<meta property="twitter:title" content="The breast cancer dataset" />
<meta property="twitter:image" content="/images/breastcancer-og-thumbnail.png" />  
<meta prefix="og: http://ogp.me/ns#" property="og:image" content="/images/breastcancer-og-thumbnail.png" />
<meta property="og:image:type" content="image/jpeg" />
<meta property="og:image:width" content="" />
<meta property="og:image:height" content="" />
<meta property="og:url" content="/post/the-breast-cancer-dataset/" />
<meta property="og:locale" content="en-us" />
<meta property="article:published_time" content="2017-10-16
" /> <meta property="article:modified_time" content="2017-10-16
" />




<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@livingwithdata" />
<meta name="twitter:creator" content="@livingwithdata" />
<meta
  name="twitter:title"
  content="The breast cancer dataset | The data salaryman"
/>
<meta
  name="twitter:description"
  content="The breast cancer dataset is a dataset of several tumor examinations. The goal of this dataset was to use the characteristics of these tumors to identify if they were harmless or potentially cancerous. Just as a radiologist (?) would use his or her experience in identifying if these tumors are good or bad, the question of this dataset is: can a machine, with enough examples, do the same as well as or better than a radiologist can?|"
/>
<meta name="twitter:image:src" content="" />
<meta name="twitter:domain" content="/post/the-breast-cancer-dataset/" />



    <title>The breast cancer dataset</title>
    <link rel="canonical" href="/post/the-breast-cancer-dataset/" />


    <link
  rel="stylesheet"
  href="https://unpkg.com/tachyons@4.11.1/css/tachyons.min.css"
/>

<link rel="stylesheet" href="/css/style.css" />

<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/highlightjs@9.12.0/styles/github-gist.css"
/>

<script src="//yihui.name/js/math-code.js"></script>
<script async 
src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-MML-AM_CHTML.js"
></script>



    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" href="/apple-touch-icon.png" />
  </head>
<body
  lang="en-us"
  class="sans-serif w-90 w-80-m w-60-ns center mv2 mv5-ns"
  itemscope
  itemtype="http://schema.org/Article"
>
  
  <span class="b">/ </span>
  <a href="/" class="b bb bw1 pb1 no-underline black">The data salaryman</a>
  <span class="b"> / </span>
  <a href="/post" class="b bb bw1 pb1 no-underline black">blog</a>

  <section id="main" class="mt5">
    <h1 itemprop="name" id="title">The breast cancer dataset</h1>
    <span class="f6 gray">October 16, 2017</span>

      <article itemprop="articleBody" id="content" class="w-90 lh-copy">
        


<p>The breast cancer dataset is a dataset of several tumor examinations. The goal of this dataset was to use the characteristics of these tumors to identify if they were harmless or potentially cancerous. Just as a radiologist (?) would use his or her experience in identifying if these tumors are good or bad, the question of this dataset is: can a machine, with enough examples, do the same as well as or better than a radiologist can?</p>
<p>In this post, I will perform a procedure that will decrease our number of variables (this datasethas nine, which would be extremely difficult to visualize). And we will be using an algorithm called logistic regression.</p>
<p>Let’s begin:</p>
<pre class="r"><code>suppressPackageStartupMessages({
  library(tidyverse)
  library(knitr)
  library(stats)
  library(modelr)
  library(gganimate)
  library(animation)
  library(png)})
# Load dataset, rename variables
read_csv(&quot;data/breastcancer.csv&quot;) %&gt;% 
  filter(X7 != &quot;?&quot;) %&gt;% 
  rename(code = X1, 
         c.thick = X2, 
         size = X3,  
         shape = X4, 
         adhes = X5, 
         sing.epith = X6, 
         bare = X7, 
         bland = X8, 
         norm = X9, 
         mitos = X10, 
         class = X11) %&gt;% 
  mutate(
    # change label to 0 or 1
    class = recode(class, `2` = 0, `4` = 1), 
    bare = as.integer(bare), 
    class = as.integer(class)) %&gt;% 
  # remove the id number
  select(-code) -&gt; breastcancer</code></pre>
<p>Let’s take a look at what this dataset looks like:</p>
<pre class="r"><code>breastcancer</code></pre>
<pre><code>## # A tibble: 683 x 10
##    c.thick  size shape adhes sing.epith  bare bland  norm mitos class
##      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;
##  1       5     1     1     1          2     1     3     1     1     0
##  2       5     4     4     5          7    10     3     2     1     0
##  3       3     1     1     1          2     2     3     1     1     0
##  4       6     8     8     1          3     4     3     7     1     0
##  5       4     1     1     3          2     1     3     1     1     0
##  6       8    10    10     8          7    10     9     7     1     1
##  7       1     1     1     1          2    10     3     1     1     0
##  8       2     1     2     1          2     1     3     1     1     0
##  9       2     1     1     1          2     1     1     1     5     0
## 10       4     2     1     1          2     1     2     1     1     0
## # … with 673 more rows</code></pre>
<p>Our y variable (class) is represented by a 1 or 0 in this dataset. The rest of the variables represent different characteristics of the tumors in question. All of these features represent a ranking from 1 to 10 of the relative magnitudes (largenesses or smallnesses) of each variable. We have a few problems with this dataset:</p>
<ol style="list-style-type: decimal">
<li><p>Since these measurements are not exactly direct measurements of the tumors, our data is strictly stuck between 1 or 10. This isn’t like ratio or interval data, this dataset behaves like ordinal data. What this means is that instead of having the data having an absolute zero (like height), or having it range freely from negative to positive values, or having decimal values, we’re stuck with positive integers {1, 2, 3, …, 10} and that’s it.</p></li>
<li><p>We have nine variables here, which means that it might become harder to predict our class. Some variables will not help us in making these predictions, and so we might need to eliminate them.</p></li>
<li><p>Having nine variables here makes it so much harder to visualize. We can’t do the Petal.length and Petal.width scatterplot graph I did in my previous post. And no, a boxplot visualization will not help, since as mentioned before, our dataset behaves ordinally.</p></li>
<li><p>The variable bare has dirty data that needs cleaning. We already filtered that in the previous code. I feel like a whole other post should be dedicated to data cleaning.</p></li>
</ol>
<p>#Exploratory Data Analysis</p>
<p>Let’s take a look at what these variables look like. We can’t use a boxplot to show this, since this isn’t continuous, it might be wise to plot a bar graph with different facets for this visualization.</p>
<p>Let’s see what that looks like for each class:</p>
<pre class="r"><code>gather(breastcancer, key, value, -class) %&gt;% 
    mutate(class = recode(class, 
                          `1` = &#39;Malignant&#39;, 
                          `0` = &#39;Benign&#39;) %&gt;% as.character()) %&gt;% 
  ggplot(aes(x = value)) + 
  geom_bar(aes(fill = class)) + 
  facet_wrap(~ key, nrow = 3, ncol = 3)</code></pre>
<p><img src="/post/breastcancer_post1_files/figure-html/unnamed-chunk-3-1.png" width="672" />
Before we take a step further, we have to make clear what we want in this visualization. Personally, from here, I want to find a way to decrease the number of variables we can work with so we can visualize their relationship in easy charts. Decreasing the number of variables (or dimensionality reduction) is normally done with more variables than now, but it would be wise for the reader to know that this exists.</p>
<p>The variables we want would show that as you increase the value of our variable, benign cases decrese (increase) and malignant cases increase (decrease). And we want to show that this relationship is smooth all the way, that for every decrease in one class, there seems to be an increase in another class.</p>
<p>Looking at the charts above, we’ll want to remove sing.epith, mitos, bland, and adhes, but before we exclude that from our model right away, we have to use a process that makes this more deliberate.</p>
<p>We’ll be finding linear combinations that maximize the variance of the predicted value. From there, we will We’re going to perform Principal Component Analysis (PCA).</p>
<pre class="r"><code>breastcancer.n &lt;- breastcancer %&gt;% 
  mutate_if(is.integer, scale)
pca &lt;- prcomp(~ adhes + 
                bare + 
                bland + 
                c.thick + 
                mitos + 
                norm + 
                shape + 
                sing.epith + 
                size, 
              data = breastcancer.n)
pca$rotation</code></pre>
<pre><code>##                  PC1          PC2         PC3         PC4         PC5
## adhes      0.3608235 -0.424769035 -0.60327873  0.48386105 -0.14176313
## bare       0.1204033  0.010204915 -0.07906976  0.04177029  0.05118314
## bland      0.3194798 -0.112970406 -0.08584491  0.07102507  0.48136784
## c.thick    0.3253806  0.863509023 -0.09505682  0.34720403 -0.08315380
## mitos      0.1416331 -0.057941664  0.06324430 -0.03702429 -0.77229299
## norm       0.3983684 -0.225601376  0.77583693  0.39955321  0.03416260
## shape      0.4343564  0.054084460 -0.03329841 -0.40503319  0.14624083
## sing.epith 0.2785702 -0.062245634  0.04342875 -0.35892504 -0.33238827
## size       0.4498282 -0.002028922 -0.06693262 -0.42970442  0.09582304
##                    PC6         PC7         PC8          PC9
## adhes       0.21741218 -0.11955455  0.00271733 -0.098211068
## bare       -0.02623682 -0.01158972  0.14677026  0.975919160
## bland      -0.76661403  0.20348390  0.04684350 -0.098713489
## c.thick    -0.01633681 -0.08067436 -0.03389756 -0.063673574
## mitos      -0.28609915  0.53995322  0.02741156  0.024942833
## norm        0.15242826 -0.06146582 -0.02534708  0.004356587
## shape       0.35071156  0.23602488  0.65226811 -0.133049977
## sing.epith -0.31110080 -0.75372049  0.10723423 -0.030845871
## size        0.19801568  0.13611938 -0.73263976  0.069590319</code></pre>
<p>Because I have the benefit of this being a really rough way to work with our data. What I’ll be doing is that I’ll be picking out the variables that show the highest coefficients in any of the components. I’ll be picking out five.
Here are the variables we will be using: mitos, c.thick, norm, bare, size</p>
<p>Let’s zoom in these variables:</p>
<pre class="r"><code>select(breastcancer, mitos, c.thick, norm, bare, size, class) %&gt;% 
  gather(key, value, -class) %&gt;% 
  mutate(class = recode(class, 
                        `1` = &#39;Malignant&#39;, 
                        `0` = &#39;Benign&#39;) %&gt;% as.character()) %&gt;% 
  ggplot(aes(value)) + 
  geom_bar(aes(fill = class)) + 
  facet_wrap(~ key, nrow = 2, ncol = 3)</code></pre>
<p><img src="/post/breastcancer_post1_files/figure-html/unnamed-chunk-6-1.png" width="672" />
All the variables except for mitos have a clear trade-off: As you increase the value, you will give up class ‘0’ for class ‘1’.</p>
<p>Let’s try making mitos interact with the other variables:</p>
<pre class="r"><code>select(breastcancer, mitos, c.thick, norm, bare, size) %&gt;% 
  gather(key, value, -mitos) %&gt;% 
  filter(value != 1 &amp; mitos != 1) %&gt;% 
  group_by(key, mitos, value) %&gt;% 
  mutate(count = n()) %&gt;% 
  ggplot(aes(x = mitos, y = value)) + 
  geom_tile(aes(fill = count)) + 
  facet_wrap(~ key, nrow = 2, ncol = 2)</code></pre>
<p><img src="/post/breastcancer_post1_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>#Train, Test Sets
A friend of mine recommended that I make a data frame of multiple training and test sets, run my model through all of them and get the average of the result. In my previous post, I made one training and testing split, but now here, we will be making 100 pairs of splits.</p>
<p>We’ll be dividing our dataset into 70% of the observations for the train set and 30% of the observations as the test set.</p>
<pre class="r"><code>set.seed(2387)
# create dataframe of train, test sets
tt.sets &lt;- select(breastcancer, bare, c.thick, norm, size, class) %&gt;% 
  crossv_mc(n = 100, test = 0.3) %&gt;% 
  mutate(ind.tr = map(train, as.integer), 
         ind.te = map(test, as.integer), 
         train.s = map(train, as_data_frame), 
         test.s = map(test, as_data_frame))
tt.sets</code></pre>
<pre><code>## # A tibble: 100 x 7
##    train     test      .id   ind.tr     ind.te     train.s        test.s        
##    &lt;list&gt;    &lt;list&gt;    &lt;chr&gt; &lt;list&gt;     &lt;list&gt;     &lt;list&gt;         &lt;list&gt;        
##  1 &lt;resampl… &lt;resampl… 001   &lt;int [478… &lt;int [205… &lt;tibble [478 … &lt;tibble [205 …
##  2 &lt;resampl… &lt;resampl… 002   &lt;int [478… &lt;int [205… &lt;tibble [478 … &lt;tibble [205 …
##  3 &lt;resampl… &lt;resampl… 003   &lt;int [478… &lt;int [205… &lt;tibble [478 … &lt;tibble [205 …
##  4 &lt;resampl… &lt;resampl… 004   &lt;int [478… &lt;int [205… &lt;tibble [478 … &lt;tibble [205 …
##  5 &lt;resampl… &lt;resampl… 005   &lt;int [478… &lt;int [205… &lt;tibble [478 … &lt;tibble [205 …
##  6 &lt;resampl… &lt;resampl… 006   &lt;int [478… &lt;int [205… &lt;tibble [478 … &lt;tibble [205 …
##  7 &lt;resampl… &lt;resampl… 007   &lt;int [478… &lt;int [205… &lt;tibble [478 … &lt;tibble [205 …
##  8 &lt;resampl… &lt;resampl… 008   &lt;int [478… &lt;int [205… &lt;tibble [478 … &lt;tibble [205 …
##  9 &lt;resampl… &lt;resampl… 009   &lt;int [478… &lt;int [205… &lt;tibble [478 … &lt;tibble [205 …
## 10 &lt;resampl… &lt;resampl… 010   &lt;int [478… &lt;int [205… &lt;tibble [478 … &lt;tibble [205 …
## # … with 90 more rows</code></pre>
<p>So how will we visualize these training and test sets? All I really want to show is that these sets are really representative samples of the whole dataset. Since we have multiple training and test splits, we will be trying to make a gif using gganimate.</p>
<pre class="r"><code>select(tt.sets, ind.tr, ind.te, .id) %&gt;% 
  gather(key = &quot;set&quot;, value = &quot;value&quot;, ind.tr, ind.te, -.id) %&gt;%
  unnest(value) %&gt;% 
  arrange(by = .id, value) %&gt;% 
  filter(.id %in% c(&quot;001&quot;, 
                    &quot;002&quot;, 
                    &quot;003&quot;, 
                    &quot;004&quot;, 
                    &quot;005&quot;, 
                    &quot;006&quot;, 
                    &quot;007&quot;)) %&gt;% 
  group_by(.id) %&gt;% 
  mutate(
    x.grid = rep(1:30, length = n()), 
    y.grid = rep(rev(1:28), each = 30, length = n()), 
    set = recode(set, 
                 &quot;ind.tr&quot; = &quot;Train&quot;, 
                 &quot;ind.te&quot; = &quot;Test&quot;)) %&gt;% 
  ungroup() %&gt;% 
  ggplot(aes(x = x.grid, y = y.grid, color = set)) + 
  geom_text(aes(label = value, group = seq_along(.id)), size = 3) + 
  transition_states(.id,
                    transition_length = 2,
                    state_length = 1)</code></pre>
<p><img src="/post/breastcancer_post1_files/figure-html/unnamed-chunk-9-1.gif" /><!-- -->
As you can see in the animation above, the red and blue text is randomly picked from whe whole dataset, which means that these train and test sets are randomly picked. This is important for us when coming up with a score for the model. We want to know if this will work well for more than just one test set.</p>
<p>#Logistical Regression
Logistic regression is a model fit for analyzing how input variables relate to the outcomes of success (1) or failure (0). The input variables don’t have to also be dummy variables (1 or 0), and can be counted variables or measured variables.</p>
<p>Logistical regression looks very similar to linear regression – y = B0 + B1*X in the sense that the form is very similar. In fact, you could be just fine doing good old linear regression. The problem is that if you draw a straight line in the middle of your observations, your predictions might not always between 1 or 0 – a big problem, because your values are only 1 or 0.</p>
<p>With the splits of train and test all ready, we can apply logistic regression on the training and test sets.</p>
<p>We implement the logistic regression algorithm with the following code:</p>
<pre class="r"><code># lgit model implementation
lgit &lt;- function(df){
  glm(class ~ ., family = binomial(link=&quot;logit&quot;), data = df)}</code></pre>
<p>In order to test the performance of our model, we will predict values from the test set using the function lgit_predict. To extract out real y variable from each test set, we will use the function lgit_response.</p>
<pre class="r"><code># predict test set
lgit_predict &lt;- function(model, df){
  preds &lt;- predict(model, newdata = select(df, -class), type = &quot;response&quot;)
  if_else(preds &gt; 0.5, 1, 0)}
# extract y values from test set
lgit_response &lt;- function(df){
  df[[&quot;class&quot;]]}</code></pre>
<p>The predictions of logistical regression are not 1 or 0 but values in between. In order to create predicted values, we simply divide our predictions between those less than 0.5 and those greater than 0.5.</p>
<p>Using the function lgit_mscore, we score how well the algorithm made the right predictions for each train and test split. We will be using the map function to apply all these functions to our nested training and test sets.</p>
<pre class="r"><code># average score
lgit_mscore &lt;- function(pred, resp){
  df &lt;- pred == resp
  mean(df)}
# create new variables
tt.sets &lt;- tt.sets %&gt;% 
  mutate(model = map(train.s, lgit), 
         pred = map2(model, test.s, lgit_predict), 
         resp = map(test.s, lgit_response), 
         hit = map2_dbl(pred, resp, lgit_mscore))
score &lt;- summarise(tt.sets, score = mean(hit))
score[[1]]</code></pre>
<pre><code>## [1] 0.9656585</code></pre>
<p>Fortunately for us, you can actually view what this model looks like. We can check out the marginal effects of our four chosen variables and we can do it for each training and test set. But that’s a blog post for another time.</p>

      </article>

      
      <span class="f6 gray mv3" title="Lastmod: October 16, 2017. Published at: 2017-10-16.">
        
      </span>

      

  </section>

  <footer>
    <div>
      <p class="f6 gray mt6 lh-copy">
        © 2019 Jose Francisco G. Endrinal
      </p>
    </div>
  </footer>
  
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.14.2/highlight.min.js"></script>

<script>
  hljs.initHighlightingOnLoad();
</script>

<script src="//yihui.name/js/math-code.js"></script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>


  </body>
</html>
