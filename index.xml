<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>The data salaryman</title>
    <link>/</link>
    <description>Recent content on The data salaryman</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>© 2019 Jose Francisco G. Endrinal</copyright>
    <lastBuildDate>Thu, 20 Jun 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>SundayStats: median()</title>
      <link>/post/sundaystats-median/</link>
      <pubDate>Thu, 20 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/sundaystats-median/</guid>
      <description>The median is a statistical measure of central tendency of a variable given an ordered position of its variables. It has several advantages over the mean. One is that it is not affected as much by extreme values, which is an advantage if you variable is very dependent on extreme values like income and number of children. R’s implementation of the median() function depends on the input, and can be controlled.</description>
    </item>
    
    <item>
      <title>About this site</title>
      <link>/about/</link>
      <pubDate>Sun, 14 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>About me Hi! You can call me Francis. I work in consulting for banks and similar companies. Much of what I do is data import, cleanup, analysis, and presentation for the clients we serve. I write this blog to document my journey in getting better at working with data, while working at a full-time job.
Me, early in the office ahead of my manager. I sent him this photo shortly after.</description>
    </item>
    
    <item>
      <title>Back to Iris: testing in R</title>
      <link>/post/back-to-iris-testing-in-r/</link>
      <pubDate>Sun, 14 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/back-to-iris-testing-in-r/</guid>
      <description>DISCLAIMER: I am not a working data analyst, nor am I a data scientist. As such, the code, techniques, and methods used in this blog post do not qualify as industry-level code, techniques, and methods. This blog and its corresponding github repository are meant to document my progress as I come to learn the techniques and skills a data analyst or data scientist will be needing in their line of work.</description>
    </item>
    
    <item>
      <title>SundayStats: A deep dive into the stats package in R - The Normal Distribution</title>
      <link>/post/sundaystats-a-deep-dive-into-the-stats-package-in-r-the-normal-distribution/</link>
      <pubDate>Sun, 14 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/sundaystats-a-deep-dive-into-the-stats-package-in-r-the-normal-distribution/</guid>
      <description>DISCLAIMER: I am not a working data analyst, nor am I a data scientist. As such, the code, techniques, and methods used in this blog post do not qualify as industry-level code, techniques, and methods. This blog and its corresponding github repository are meant to document my progress as I come to learn the techniques and skills a data analyst or data scientist will be needing in their line of work.</description>
    </item>
    
    <item>
      <title>Wasted on data: Exploring the wine dataset</title>
      <link>/post/wasted-on-data-exploring-the-wine-dataset/</link>
      <pubDate>Tue, 19 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/wasted-on-data-exploring-the-wine-dataset/</guid>
      <description>Whether you’re a drinker or not, chances are that alcohol has played some part in the culture of where you live. It would be awesome to take measurements on any wine and be able to determine what kind of wine it was. In this dataset, we’re sticking with three unidentified types of wine.
The wine dataset is a series of measurements of different samples of three types of wine. In this dataset, there are thirteen characteristics that were measured: 1.</description>
    </item>
    
    <item>
      <title>The MRT dataset: A Case in Exploratory Data Analysis</title>
      <link>/post/the-mrt-dataset-a-case-in-exploratory-data-analysis/</link>
      <pubDate>Wed, 09 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/the-mrt-dataset-a-case-in-exploratory-data-analysis/</guid>
      <description>The Metro Rail Transit (MRT) is a light rail transit system in Metro Manila, Philippines that runs along Epifanio delos Santos Avenue (EDSA) from Taft Avenue Station in Manila, to North Avenue Station in Quezon City. This dataset is the hourly traffic of passengers going in and out of turnstiles at the different train stations covering the years 2012 to 2014.
I cleaned up this dataset before I put it here so that we can do exploratory data analysis (EDA) straightaway.</description>
    </item>
    
    <item>
      <title>Restarting and Clearing</title>
      <link>/post/restarting-and-clearing/</link>
      <pubDate>Tue, 24 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/restarting-and-clearing/</guid>
      <description>Introduction I’m trying so hard to get people on the bandwagon of clearing and restarting their R sessions frequently. If there’s anything you can do to ensure the integrity of your code, it’s restarting the R session, clearing your console screen, and re-running your code.
This practice ensures that you always start from a clean slate when you run your analysis. If you start your analysis with objects in your workspace and your code relies on that workspace, chances are that your analysis will fail to deliver, or you get unexpected (often wrong) results from the code you just run.</description>
    </item>
    
    <item>
      <title>The breast cancer dataset</title>
      <link>/post/the-breast-cancer-dataset/</link>
      <pubDate>Mon, 16 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/the-breast-cancer-dataset/</guid>
      <description>The breast cancer dataset is a dataset of several tumor examinations. The goal of this dataset was to use the characteristics of these tumors to identify if they were harmless or potentially cancerous. Just as a radiologist (?) would use his or her experience in identifying if these tumors are good or bad, the question of this dataset is: can a machine, with enough examples, do the same as well as or better than a radiologist can?</description>
    </item>
    
    <item>
      <title>Exploring the Iris Dataset</title>
      <link>/post/exploring-the-iris-dataset/</link>
      <pubDate>Tue, 05 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/exploring-the-iris-dataset/</guid>
      <description>One of the most common example datasets that I came across in my journey into the data science world is called Iris. The dataset is a record of feature measurements (petal lengths and widths, sepal lengths and widths) of different species of Iris flowers. It is often used to demonstrate simple machine learning techniques.
Many versions of this dataset exist, but we will be using the data found here.</description>
    </item>
    
  </channel>
</rss>